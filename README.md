## Introduction
This is the code for the genetic algorithm for automated prompt engineering. The algorithm divides the initial prompt into multiple sentences which are treated as the genes of each chromosome or prompt. The mutator itself is an LLM specifically fine tuned for sentence rephrasing. The detailed overview of the algorithm can be found in the documentation.

## Usage
Download the folder "ga" and install all the dependencies. The dependencies can be installed via 
`pip install -r requirements.txt`
after navigating into the ga directory. The required dependencies include

* `numpy`
* `pandas`
* `torch`
* `transformers`
* `sentence-transformers`
* `fastapi`
* `kaleido`
* `python-multipart`
* `pyhypercycle_aim`

### Running the algorithm and getting the best prompt
After installing all the dependencies, run the `ga.py` file from the terminal. The algorithm would save the best prompts into `best_prompt.txt` file along with the history generated by the mutator in `history.csv`.

### Inference
Furter inference can be carried out using `generate_answer()` function of a `GA` instance.

#### Note
Currently only the *causal judgment* dataset and the corresponding template is supported from the *Big Bench Hard* is available as a default. More datasets would be added in future versions.

### Custom dataset and templates
To perform inference on custom dataset use the `Dataset` and `Template` classes. The classes provides utilities for creating a setting up a custom dataset and templates for the prompts. 

To create load a custom template use the `Template` class. The constructor accepts two arguments, the file path of the templates for demo and the actual prompt. Only `.txt` files are supported for templates. The available placeholders are, 

* `[question]`
* `[instruction]`
* `[context]`
* `[demos]`

While the placeholders have a semantic meaning, they can be used arbitarily inside the templates.

To create a custom dataset, first create a `Template` instance. This instance ould be used to create inputs for the model from the questions in the dataset. Without a template instance provided the `Dataset` class would use the default templates for causal judement tasks. These can be found in the templates folder and are named `context`. The dataset formats supported are, 

* `.json`
* python `dict` or `list` of `dict`
* `.csv`

The dataset must contain at least two columns, named `input`, containing the input questions single or `list` as per format chosen and `target`, contiaing the targets for the inputs.

### Default fitness function
The default fitness function expects the answers generated by the model for the questions to be texts containing "answer is [ans]" at the end of the text. The "[ans]" could be `Yes` or `No`. The fitness is evaluated using the accuracy. Refer to documentation for more details.

### Custom fitness functions
The model supports custom fitness functions. To specify a fitness function, pass it using `fitness_func` argument in the `GA` class. The fitness function must accept at least two arguments, 

* First: `prompt`: the prompt to be evaluated
* Second: `df`: dataset to evaluate the score

The return value of the fitness function must be either a `float` or coersable into `float`.

### LLMs supported
The `GA` class supports only *T5* models from google flan, including `[t5-small, t5-base, t5-large`]. Support for more models would be added in future releases.

#### Note
Since all the computation is perfomed on the CPUs, the number of models were restricted to small subsets to prevent crahes.